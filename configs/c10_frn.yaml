eval:
  eval_seed: 0
  lopt: l2e
  lopt_path: ./result/meta_training/l2e_icml
  task: c10_frn
  batch_size: 128
  num_epoch: 600
  thin: 50
  burn_in: 100
  alpha: 0.1
  init_lr: 0.1
  cycle_epochs: 50
  wd: 0.0005
  step_mult: 2.0


